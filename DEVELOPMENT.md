# CAAC è§„ç« æ›´æ–°ç›‘æ§ - å¼€å‘æŒ‡å—

> æœ¬æ–‡æ¡£ä¸º AI å¼€å‘åŠ©æ‰‹æä¾›å®Œæ•´çš„é¡¹ç›®èƒŒæ™¯ã€æŠ€æœ¯å†³ç­–å’Œå®ç°æŒ‡å—
> 
> **é‡è¦**: å¼€å‘å‰è¯·ä»”ç»†é˜…è¯»æœ¬æ–‡æ¡£ï¼ŒåŒ…å«å¤§é‡ç»è¿‡éªŒè¯çš„æŠ€æœ¯ç»†èŠ‚å’Œé¿å‘æŒ‡å—

---

## ä»£ç å®¡æŸ¥ä¿®å¤è®°å½• (2025-01-28)

åŸºäº Google AI æœç´¢ç»“æœï¼Œå¯¹ä»£ç è¿›è¡Œäº†ä»¥ä¸‹ä¼˜åŒ–ï¼š

### crawler.py
1. **æµè§ˆå™¨å®ä¾‹å¤ç”¨** - é¿å…æ¯æ¬¡è¯·æ±‚éƒ½å¯åŠ¨æ–°æµè§ˆå™¨ï¼Œæ”¹ä¸ºå¤ç”¨ Browser å®ä¾‹ï¼Œåªåˆ›å»ºæ–° Context
2. **é‡è¯•æœºåˆ¶** - æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•ï¼ˆ3 æ¬¡ï¼‰ï¼Œå¤„ç†ç½‘ç»œæ³¢åŠ¨
3. **æµå¼ PDF ä¸‹è½½** - ä½¿ç”¨ `httpx.stream()` + `iter_bytes(chunk_size=8192)`ï¼Œé¿å…å¤§æ–‡ä»¶å†…å­˜æº¢å‡º
4. **ç²¾ç»†åŒ–è¶…æ—¶é…ç½®** - `httpx.Timeout(connect=10.0, read=60.0, write=30.0, pool=10.0)`
5. **CI è¶…æ—¶å¢åŠ ** - `page.goto()` è¶…æ—¶ä» 30s å¢åŠ åˆ° 60sï¼Œé€‚åº” GitHub Actions 2 æ ¸ CPU

### storage.py
6. **JSON æŸåå¤‡ä»½** - è§£æå¤±è´¥æ—¶è‡ªåŠ¨å¤‡ä»½æŸåæ–‡ä»¶åˆ° `.corrupted.{timestamp}`

### notifier.py
7. **Telegram MarkdownV2 è½¬ä¹‰** - æ­£ç¡®è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ `_*[]()~\`>#+-=|{}.!`

### main.py
8. **é€€å‡ºç è§„èŒƒ** - 0=æˆåŠŸ, 1=å¤±è´¥, 130=ç”¨æˆ·ä¸­æ–­
9. **å¼‚å¸¸å †æ ˆæ—¥å¿—** - ä½¿ç”¨ `traceback.format_exc()` è®°å½•å®Œæ•´å †æ ˆ

### workflow YAML
10. **ç³»ç»Ÿä¾èµ–å®‰è£…** - `patchright install --with-deps chromium` å®‰è£… libgbm ç­‰
11. **è¶…æ—¶ç¯å¢ƒå˜é‡** - æ·»åŠ  `PLAYWRIGHT_TIMEOUT: "60000"`

---

## é¡¹ç›®æ¦‚è¿°

### ç›®æ ‡

è‡ªåŠ¨ç›‘æ§ä¸­å›½æ°‘èˆªå±€ï¼ˆCAACï¼‰å®˜ç½‘çš„è§„ç« æ›´æ–°ï¼Œå‘ç°æ–°å¢æˆ–ä¿®æ”¹çš„è§„ç« æ—¶ï¼š
1. è‡ªåŠ¨ä¸‹è½½ PDF æ–‡ä»¶ï¼ˆè§„èŒƒåŒ–å‘½åï¼‰
2. å‘é€é‚®ä»¶/æ¨é€é€šçŸ¥
3. è®°å½•å˜æ›´å†å²

### è¿è¡Œç¯å¢ƒ

- **å¹³å°**: GitHub Actionsï¼ˆæ¯æ—¥å®šæ—¶è¿è¡Œï¼‰
- **è¯­è¨€**: Python 3.12+
- **åŒ…ç®¡ç†**: uvï¼ˆä¸æ˜¯ pipï¼ï¼‰
- **æµè§ˆå™¨**: Patchrightï¼ˆåæ£€æµ‹ Playwrightï¼‰

---

## æŠ€æœ¯é€‰å‹å†³ç­–

### ä¸ºä»€ä¹ˆé€‰ Python è€Œä¸æ˜¯ Rustï¼Ÿ

| ç»´åº¦ | Python + Patchright | Rust |
|------|---------------------|------|
| **åçˆ¬èƒ½åŠ›** | â­â­â­â­â­ Patchright å†…æ ¸çº§åæ£€æµ‹ | â­â­ æ— ç­‰æ•ˆå·¥å…· |
| **å¼€å‘é€Ÿåº¦** | â­â­â­â­â­ æœ‰ç°æˆä»£ç å¯å¤ç”¨ | â­â­ éœ€å…¨éƒ¨é‡å†™ |
| **CI ç¼–è¯‘** | â­â­â­â­â­ é›¶ç¼–è¯‘ | â­â­ 5-10 åˆ†é’Ÿæ¶ˆè€— Actions é…é¢ |
| **ç”Ÿæ€æˆç†Ÿåº¦** | â­â­â­â­â­ BeautifulSoup ç­‰ | â­â­â­ å¯ç”¨ä½†ä¸å¦‚ Python |

**å…³é”®åŸå› **: CAAC å®˜ç½‘æœ‰å®‰å…¨ç‹—é˜²æŠ¤ï¼ŒPatchright æ˜¯ç›®å‰æœ€å¼ºçš„åæ£€æµ‹æ–¹æ¡ˆï¼ŒRust ç”Ÿæ€æ²¡æœ‰å¯¹ç­‰å·¥å…·ï¼ˆchromiumoxide åªæ˜¯ CDP å°è£…ï¼Œæ— åæ£€æµ‹èƒ½åŠ›ï¼‰ã€‚

### ä¸ºä»€ä¹ˆç”¨ Patchright è€Œä¸æ˜¯ Playwrightï¼Ÿ

| ç‰¹æ€§ | Playwright (åŸç”Ÿ) | Patchright (åæ£€æµ‹ç‰ˆ) |
|------|-------------------|----------------------|
| åæ£€æµ‹æ ¸å¿ƒ | ä¾èµ–æ’ä»¶ï¼ˆå¦‚ playwright-stealthï¼‰ | **å†…æ ¸çº§ä¿®æ”¹**ï¼Œç§»é™¤ CDP æ³„éœ² |
| ç»•è¿‡ WAF èƒ½åŠ› | å®¹æ˜“è¢«é«˜çº§ WAF è¯†åˆ« | **ä¸“ä¸ºç»•è¿‡ Cloudflare/å®‰å…¨ç‹—è®¾è®¡** |
| ç‰¹å¾æ¸…é™¤ | éœ€æ‰‹åŠ¨ä¿®æ”¹ JS ç¯å¢ƒï¼Œä¸å½»åº• | è‡ªåŠ¨æ¸…é™¤ `webdriver: true` åŠäºŒè¿›åˆ¶ç‰¹å¾ |
| API å…¼å®¹æ€§ | å®˜æ–¹æ”¯æŒ | **100% ç»§æ‰¿ Playwright API**ï¼Œé›¶æˆæœ¬è¿ç§» |

### ä¸ºä»€ä¹ˆç”¨ httpx è€Œä¸æ˜¯ requestsï¼Ÿ

| ç‰¹æ€§ | requests | httpx |
|------|----------|-------|
| å¼‚æ­¥æ”¯æŒ | âŒ ä»…åŒæ­¥ | âœ… åŸç”Ÿ async/await |
| HTTP/2 | âŒ ä»… HTTP/1.1 | âœ… æ”¯æŒ |
| ç±»å‹æç¤º | âŒ æ—  | âœ… å®Œæ•´ç±»å‹æ³¨è§£ |
| è¿æ¥æ±  | åŸºç¡€ | æ›´é«˜æ•ˆï¼Œé€‚åˆé«˜å¹¶å‘ |

**æœ¬é¡¹ç›®é€‰æ‹©**: ä½¿ç”¨ httpx è¿›è¡Œ PDF ä¸‹è½½ç­‰ HTTP è¯·æ±‚ï¼ŒPatchright ç”¨äºè·å–åŠ¨æ€æ¸²æŸ“é¡µé¢ã€‚

---

## Patchright ä½¿ç”¨è¯¦è§£

### å®‰è£…

```bash
# å®‰è£… patchright åŒ…
uv add patchright

# å®‰è£…ä¿®æ”¹ç‰ˆæµè§ˆå™¨å†…æ ¸ï¼ˆå¿…é¡»ï¼ï¼‰
uv run patchright install chromium
```

### Sync vs Async API

Patchright æä¾›ä¸¤ç§ API é£æ ¼ï¼š

| ç‰¹æ€§ | åŒæ­¥ API (Sync) | å¼‚æ­¥ API (Async) |
|------|----------------|------------------|
| å¯¼å…¥ | `from patchright.sync_api import sync_playwright` | `from patchright.async_api import async_playwright` |
| ä»£ç é£æ ¼ | é¡ºåºæ‰§è¡Œï¼Œç›´è§‚æ˜“è¯» | ä½¿ç”¨ `async/await`ï¼ŒåŸºäºåç¨‹ |
| å¹¶å‘èƒ½åŠ› | é˜»å¡å¼ï¼Œå•çº¿ç¨‹ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªä»»åŠ¡ | éé˜»å¡ï¼Œé«˜æ•ˆå¤„ç†å¤§é‡å¹¶å‘ |
| é€‚ç”¨åœºæ™¯ | ç®€å•è„šæœ¬ã€åˆå­¦è€… | ç”Ÿäº§çº§çˆ¬è™«ã€é›†æˆåˆ°å¼‚æ­¥æ¡†æ¶ |

**æœ¬é¡¹ç›®é€‰æ‹©**: ä½¿ç”¨ **åŒæ­¥ API**ï¼Œå› ä¸ºæ¯å¤©åªè·‘ä¸€æ¬¡ï¼Œä¸éœ€è¦é«˜å¹¶å‘ã€‚

### åŒæ­¥ API ä»£ç ç¤ºä¾‹

```python
from patchright.sync_api import sync_playwright

def fetch_page(url: str) -> str:
    """ä½¿ç”¨ Patchright è·å–é¡µé¢å†…å®¹"""
    with sync_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆheadless=True æ— å¤´æ¨¡å¼ï¼‰
        browser = p.chromium.launch(headless=True)
        try:
            page = browser.new_page()
            # wait_until="networkidle" ç­‰å¾…ç½‘ç»œç©ºé—²
            page.goto(url, wait_until="networkidle", timeout=30000)
            return page.content()
        finally:
            browser.close()
```

### åæ£€æµ‹éªŒè¯

å¯ä»¥ç”¨ä»¥ä¸‹ç½‘ç«™æµ‹è¯•åæ£€æµ‹æ•ˆæœï¼š
- https://bot.sannysoft.com - æ£€æµ‹ WebDriver ç‰¹å¾
- https://nowsecure.nl - Cloudflare æ£€æµ‹
- https://browserleaks.com/javascript - JS æŒ‡çº¹æ£€æµ‹

---

## å‚è€ƒå®ç°

### 1. CAAC çˆ¬è™«å‚è€ƒ

**æ–‡ä»¶**: `D:\screenshot\HuGeScreenshot-tauri\python\huge_sidecar\services\regulation_service.py`

å…³é”®ä»£ç ç‰‡æ®µï¼š

```python
# CAAC å®˜ç½‘é…ç½®
BASE_URL = "https://www.caac.gov.cn"
WAS5_SEARCH_URL = "https://www.caac.gov.cn/was5/web/search"

# é¢‘é“ ID
REGULATION_CHANNEL = "269689"  # æ°‘èˆªè§„ç« é¢‘é“
NORMATIVE_CHANNEL = "238066"   # è§„èŒƒæ€§æ–‡ä»¶é¢‘é“

# åˆ†ç±» ID (fl å‚æ•°)
REGULATION_FL = "13"   # æ°‘èˆªè§„ç« åˆ†ç±»
NORMATIVE_FL = "14"    # è§„èŒƒæ€§æ–‡ä»¶åˆ†ç±»
```

**æœç´¢ URL æ„é€ **:
```python
# è§„ç« æœç´¢
f"{WAS5_SEARCH_URL}?channelid={REGULATION_CHANNEL}&perpage=100&orderby=-fabuDate&fl={REGULATION_FL}"

# è§„èŒƒæ€§æ–‡ä»¶æœç´¢
f"{WAS5_SEARCH_URL}?channelid={NORMATIVE_CHANNEL}&perpage=100&orderby=-fabuDate&fl={NORMATIVE_FL}"
```

**æµè§ˆå™¨è·å–é¡µé¢**:
```python
def _fetch_with_browser(self, url: str, browser_type: str) -> str:
    if browser_type == "patchright":
        from patchright.sync_api import sync_playwright
    else:
        from playwright.sync_api import sync_playwright

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        try:
            page = browser.new_page()
            page.goto(url, wait_until="networkidle", timeout=30000)
            return page.content()
        finally:
            browser.close()
```

### 2. é€šçŸ¥ç³»ç»Ÿå‚è€ƒ

**æ–‡ä»¶**: `D:\sign-in\utils\notify.py`

æ”¯æŒçš„é€šçŸ¥æ¸ é“ï¼š
- Emailï¼ˆQQ é‚®ç®±ï¼‰- **ä¸»è¦ä½¿ç”¨**
- PushPlus
- Serveré…± Turbo (SCT)
- Telegram
- é’‰é’‰ã€é£ä¹¦ã€ä¼ä¸šå¾®ä¿¡
- Bark (iOS)

**QQ é‚®ç®±å…³é”®é…ç½®**:
```python
# From å­—æ®µå¿…é¡»ä½¿ç”¨è¿™ä¸ªæ ¼å¼ï¼Œå¦åˆ™ 502 é”™è¯¯
msg["From"] = formataddr((Header(sender_name, "utf-8").encode(), self.email_user))

# SMTP æœåŠ¡å™¨
smtp_server = "smtp.qq.com"  # æˆ–ä»é‚®ç®±åŸŸåæ¨æ–­

# ä½¿ç”¨ SSL ç«¯å£ 465
with smtplib.SMTP_SSL(smtp_server, 465) as server:
    server.login(self.email_user, self.email_pass)
    server.sendmail(...)
```

### 3. GitHub Actions å‚è€ƒ

**æ–‡ä»¶**: `D:\sign-in\.github\workflows\daily-check-in.yml`

å…³é”®é…ç½®ï¼š
```yaml
runs-on: ubuntu-22.04

steps:
  # ä½¿ç”¨ uv è€Œä¸æ˜¯ pip
  - name: Install uv
    uses: astral-sh/setup-uv@v4
    with:
      version: "latest"
  
  - name: Set up Python
    run: uv python install 3.12
  
  - name: Install dependencies
    run: uv sync
  
  # å®‰è£… Patchright æµè§ˆå™¨
  - name: Install Patchright browsers
    run: uv run patchright install chromium
```

---

## BeautifulSoup è§£ææœ€ä½³å®è·µ

### å¤„ç†ä¸­æ–‡ç¼–ç 

```python
from bs4 import BeautifulSoup

# âœ… æ­£ç¡®ï¼šä¼ å…¥äºŒè¿›åˆ¶å†…å®¹ï¼Œè®© BS4 è‡ªåŠ¨æ£€æµ‹ç¼–ç 
html_content = page.content()  # Patchright è¿”å›çš„æ˜¯å­—ç¬¦ä¸²
soup = BeautifulSoup(html_content, "lxml")

# å¦‚æœæ˜¯ requests/httpx è·å–çš„å“åº”
response = httpx.get(url)
soup = BeautifulSoup(response.content, "lxml")  # ç”¨ .content ä¸æ˜¯ .text

# å¦‚æœè‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œæ‰‹åŠ¨æŒ‡å®šç¼–ç 
soup = BeautifulSoup(response.content, "lxml", from_encoding="gb18030")
```

### find_all vs select

| æ–¹æ³• | è¯­æ³•é£æ ¼ | ç¤ºä¾‹ | é€‚ç”¨åœºæ™¯ |
|------|----------|------|----------|
| `find_all()` | Pythonic API | `soup.find_all("a", class_="link")` | éœ€è¦æ­£åˆ™åŒ¹é…ã€è‡ªå®šä¹‰å‡½æ•°è¿‡æ»¤ |
| `select()` | CSS é€‰æ‹©å™¨ | `soup.select("a.link")` | å¤æ‚å±‚çº§å®šä½ï¼Œç†Ÿæ‚‰ CSS è¯­æ³• |

```python
# find_all ç¤ºä¾‹
rows = soup.find_all("tr")
links = soup.find_all("a", href=True)
cells = row.find_all("td", class_="t_l")

# select ç¤ºä¾‹ï¼ˆCSS é€‰æ‹©å™¨ï¼‰
rows = soup.select("table.t_table tbody tr")
links = soup.select("a[href$='.pdf']")  # href ä»¥ .pdf ç»“å°¾
```

---

## æ–‡ä»¶åè§„èŒƒ

### æ ¼å¼

```
{æ–‡å·}{æ ‡é¢˜}.pdf
```

### ç¤ºä¾‹

```
CCAR-91-R4ä¸€èˆ¬è¿è¡Œå’Œé£è¡Œè§„åˆ™.pdf
AC-91-FS-041èˆªç©ºå™¨è¿è¡Œ-èˆªç©ºå™¨æ“ä½œç¨‹åº.pdf
å¤±æ•ˆ!CCAR-121-R6å¤§å‹é£æœºå…¬å…±èˆªç©ºè¿è¾“æ‰¿è¿äººè¿è¡Œåˆæ ¼å®¡å®šè§„åˆ™.pdf
```

### ç”Ÿæˆé€»è¾‘

```python
def generate_filename(document: RegulationDocument) -> str:
    def sanitize(text: str) -> str:
        """æ›¿æ¢æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
        return re.sub(r'[<>:"/\\|?*]', '_', text)

    parts = []

    # æœ‰æ•ˆæ€§å‰ç¼€ï¼ˆå¤±æ•ˆçš„åŠ å‰ç¼€ï¼‰
    validity = document.validity.strip()
    if validity in ("å¤±æ•ˆ", "åºŸæ­¢"):
        parts.append("å¤±æ•ˆ!")

    # æ–‡å·
    doc_number = sanitize(document.doc_number.strip())
    if doc_number:
        parts.append(doc_number)

    # æ ‡é¢˜
    title = sanitize(document.title.strip())
    parts.append(title)

    filename = "".join(parts) + ".pdf"

    # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    if len(filename) > 200:
        filename = filename[:197] + "....pdf"

    return filename
```

---

## æ•°æ®æ¨¡å‹

### RegulationDocument

```python
@dataclass
class RegulationDocument:
    title: str           # æ–‡æ¡£æ ‡é¢˜
    url: str             # è¯¦æƒ…é¡µ URL
    validity: str        # "æœ‰æ•ˆ", "å¤±æ•ˆ", "åºŸæ­¢"
    doc_number: str      # æ–‡å·ï¼ˆå¦‚ CCAR-121-R7ï¼‰
    office_unit: str     # å‘å¸ƒå•ä½
    doc_type: str        # "regulation" è§„ç« , "normative" è§„èŒƒæ€§æ–‡ä»¶
    sign_date: str       # ç­¾å‘æ—¥æœŸ (YYYY-MM-DD)
    publish_date: str    # å‘å¸ƒæ—¥æœŸ (YYYY-MM-DD)
    pdf_url: str         # PDF é™„ä»¶é“¾æ¥
```

### çŠ¶æ€å­˜å‚¨ (data/regulations.json)

```json
{
  "last_check": "2025-01-28T08:00:00",
  "regulations": [
    {
      "url": "https://www.caac.gov.cn/...",
      "doc_number": "CCAR-91-R4",
      "title": "ä¸€èˆ¬è¿è¡Œå’Œé£è¡Œè§„åˆ™",
      "validity": "æœ‰æ•ˆ",
      "publish_date": "2024-01-15",
      "sha256": "abc123..."
    }
  ],
  "normatives": [...]
}
```

---

## æ ¸å¿ƒæµç¨‹

```
1. çˆ¬å– CAAC å®˜ç½‘è§„ç« åˆ—è¡¨
   â”œâ”€â”€ ä½¿ç”¨ Patchright ç»•è¿‡å®‰å…¨ç‹—
   â”œâ”€â”€ è§£æè§„ç« åˆ—è¡¨é¡µ HTML
   â””â”€â”€ æå–æ–‡æ¡£å…ƒæ•°æ®

2. å¯¹æ¯”å†å²çŠ¶æ€
   â”œâ”€â”€ è¯»å– data/regulations.json
   â”œâ”€â”€ æ£€æµ‹æ–°å¢æ–‡æ¡£ï¼ˆURL ä¸å­˜åœ¨ï¼‰
   â””â”€â”€ æ£€æµ‹æ›´æ–°æ–‡æ¡£ï¼ˆSHA256 å˜åŒ–ï¼‰

3. å¤„ç†å˜æ›´
   â”œâ”€â”€ ä¸‹è½½æ–°å¢/æ›´æ–°çš„ PDF
   â”œâ”€â”€ è§„èŒƒåŒ–æ–‡ä»¶å
   â””â”€â”€ ä¿å­˜åˆ° downloads/

4. å‘é€é€šçŸ¥
   â”œâ”€â”€ ç”Ÿæˆå˜æ›´æ‘˜è¦
   â”œâ”€â”€ å‘é€é‚®ä»¶ï¼ˆQQ é‚®ç®±ï¼‰
   â””â”€â”€ å¯é€‰ï¼šPushPlus/Telegram ç­‰

5. æ›´æ–°çŠ¶æ€
   â”œâ”€â”€ æ›´æ–° data/regulations.json
   â””â”€â”€ Git commit + push
```

---

## ç›®å½•ç»“æ„

```
CCAR-workflow/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ check-updates.yml    # GitHub Actions å·¥ä½œæµ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler.py               # CAAC çˆ¬è™«ï¼ˆPatchrightï¼‰
â”‚   â”œâ”€â”€ notifier.py              # é€šçŸ¥ç®¡ç†
â”‚   â”œâ”€â”€ storage.py               # çŠ¶æ€å­˜å‚¨å’Œå¯¹æ¯”
â”‚   â””â”€â”€ main.py                  # ä¸»å…¥å£
â”œâ”€â”€ data/
â”‚   â””â”€â”€ regulations.json         # è§„ç« çŠ¶æ€æ•°æ®
â”œâ”€â”€ downloads/                   # PDF ä¸‹è½½ç›®å½•ï¼ˆ.gitignoreï¼‰
â”œâ”€â”€ pyproject.toml               # é¡¹ç›®ä¾èµ–
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                    # ç”¨æˆ·æ–‡æ¡£
â””â”€â”€ DEVELOPMENT.md               # å¼€å‘æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```

---

## JSON æ–‡ä»¶è¯»å†™æœ€ä½³å®è·µ

### é˜²æ­¢ä¸­æ–‡ä¹±ç 

```python
import json

data = {"title": "ä¸€èˆ¬è¿è¡Œå’Œé£è¡Œè§„åˆ™", "doc_number": "CCAR-91-R4"}

# âœ… æ­£ç¡®ï¼šensure_ascii=False + encoding="utf-8"
with open("data.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# âŒ é”™è¯¯ï¼šä¸­æ–‡ä¼šå˜æˆ \uXXXX
with open("data.json", "w") as f:
    json.dump(data, f)  # ç¼ºå°‘ ensure_ascii=False
```

### åŸå­å†™å…¥ï¼ˆé˜²æ­¢æ•°æ®æŸåï¼‰

æ™®é€šçš„ `open(..., 'w')` ä¼šåœ¨å†™å…¥å¼€å§‹æ—¶ç«‹å³æ¸…ç©ºåŸæ–‡ä»¶ã€‚å¦‚æœç¨‹åºå´©æºƒï¼Œæ•°æ®ä¼šä¸¢å¤±ã€‚

```python
import json
import os
import tempfile

def atomic_write_json(file_path: str, data: dict) -> None:
    """åŸå­å†™å…¥ JSON æ–‡ä»¶ï¼Œé˜²æ­¢æ•°æ®æŸå"""
    dir_name = os.path.dirname(file_path) or "."
    
    # 1. å†™å…¥ä¸´æ—¶æ–‡ä»¶
    fd, temp_path = tempfile.mkstemp(dir=dir_name, suffix=".tmp")
    try:
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())  # å¼ºåˆ¶åŒæ­¥åˆ°ç¡¬ç›˜
        
        # 2. åŸå­æ›¿æ¢ï¼ˆè¦ä¹ˆæˆåŠŸï¼Œè¦ä¹ˆä¿ç•™åŸæ–‡ä»¶ï¼‰
        os.replace(temp_path, file_path)
    except Exception:
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise
```

---

## QQ é‚®ç®±å‘é€è¯¦è§£

### è·å–æˆæƒç ï¼ˆå¿…é¡»ï¼ï¼‰

1. ç™»å½• QQ é‚®ç®±ç½‘é¡µç‰ˆ
2. ç‚¹å‡» **è®¾ç½®** â†’ **è´¦å·**
3. æ‰¾åˆ° **POP3/IMAP/SMTP/Exchange/CardDAV/CalDAVæœåŠ¡**
4. ç‚¹å‡» **å¼€å¯ POP3/SMTPæœåŠ¡**
5. æ ¹æ®æç¤ºå‘é€çŸ­ä¿¡éªŒè¯
6. è·å¾— **16 ä½å­—æ¯æˆæƒç **ï¼ˆä¸æ˜¯ QQ å¯†ç ï¼ï¼‰

### å‘é€é‚®ä»¶ä»£ç 

```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr

def send_email(
    email_user: str,      # QQ é‚®ç®±è´¦å·
    email_pass: str,      # 16 ä½æˆæƒç ï¼ˆä¸æ˜¯å¯†ç ï¼ï¼‰
    email_to: str,        # æ”¶ä»¶äºº
    subject: str,         # ä¸»é¢˜
    content: str,         # å†…å®¹
    sender_name: str = "CAAC è§„ç« ç›‘æ§"  # å‘ä»¶äººæ˜¾ç¤ºåç§°
) -> None:
    """å‘é€ QQ é‚®ç®±"""
    
    # åˆ›å»ºé‚®ä»¶
    msg = MIMEMultipart("alternative")
    msg.attach(MIMEText(content, "html", "utf-8"))
    
    # âš ï¸ From å­—æ®µæ ¼å¼å¿…é¡»æ­£ç¡®ï¼Œå¦åˆ™ 502 é”™è¯¯
    msg["From"] = formataddr((Header(sender_name, "utf-8").encode(), email_user))
    msg["To"] = email_to
    msg["Subject"] = Header(subject, "utf-8")
    
    # ä½¿ç”¨ SSL 465 ç«¯å£ï¼ˆä¸æ˜¯ 587ï¼ï¼‰
    with smtplib.SMTP_SSL("smtp.qq.com", 465) as server:
        server.login(email_user, email_pass)
        server.sendmail(email_user, [email_to], msg.as_string())
```

### å¸¸è§é”™è¯¯

| é”™è¯¯ç  | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|--------|------|----------|
| **535** | æˆæƒç é”™è¯¯æˆ–æœªå¼€å¯ SMTP | æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ 16 ä½æˆæƒç ï¼Œç¡®è®¤ SMTP å·²å¼€å¯ |
| **554** | é‚®ä»¶è¢«åˆ¤å®šä¸ºåƒåœ¾é‚®ä»¶ | ç¡®ä¿è®¾ç½®äº† From/To/Subjectï¼Œé¿å…æ•æ„Ÿè¯ |
| **502** | From å­—æ®µæ ¼å¼é”™è¯¯ | ä½¿ç”¨ `formataddr()` æ­£ç¡®æ ¼å¼åŒ– |

---

## GitHub Actions è¯¦è§£

### Cron è¡¨è¾¾å¼

GitHub Actions ä½¿ç”¨ **UTC æ—¶é—´**ï¼ŒåŒ—äº¬æ—¶é—´ = UTC + 8 å°æ—¶ã€‚

```yaml
on:
  schedule:
    # æ ¼å¼ï¼šåˆ† æ—¶ æ—¥ æœˆ å‘¨
    - cron: '0 0 * * *'   # UTC 00:00 = åŒ—äº¬æ—¶é—´ 08:00
    - cron: '0 16 * * *'  # UTC 16:00 = åŒ—äº¬æ—¶é—´ 00:00ï¼ˆæ¬¡æ—¥ï¼‰
```

| ç›®æ ‡åŒ—äº¬æ—¶é—´ | Cron è¡¨è¾¾å¼ (UTC) |
|-------------|-------------------|
| æ¯å¤© 00:00 | `0 16 * * *` |
| æ¯å¤© 08:00 | `0 0 * * *` |
| æ¯å¤© 12:00 | `0 4 * * *` |
| æ¯å¤© 20:00 | `0 12 * * *` |

### Schedule ä¸è§¦å‘çš„å¸¸è§åŸå› 

1. **æ‰§è¡Œå»¶è¿Ÿ**ï¼ˆæœ€å¸¸è§ï¼‰ï¼šGitHub ä¸ä¿è¯å‡†æ—¶ï¼Œå¯èƒ½å»¶è¿Ÿå‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶
2. **åˆ†æ”¯é™åˆ¶**ï¼šschedule å¿…é¡»åœ¨é»˜è®¤åˆ†æ”¯ï¼ˆmain/masterï¼‰ä¸­å®šä¹‰
3. **ä»“åº“ä¸æ´»è·ƒ**ï¼šè¶…è¿‡ 60 å¤©æ— æ´»åŠ¨ä¼šè‡ªåŠ¨æš‚åœ
4. **è¯­æ³•é”™è¯¯**ï¼šYAML æ ¼å¼ä¸æ­£ç¡®

### è§£å†³æ–¹æ¡ˆ

```yaml
on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:  # æ·»åŠ æ‰‹åŠ¨è§¦å‘ï¼Œæ–¹ä¾¿è°ƒè¯•
```

---

## Loguru æ—¥å¿—é…ç½®

```python
import sys
from loguru import logger

# ç§»é™¤é»˜è®¤é…ç½®
logger.remove()

# æ§åˆ¶å°è¾“å‡ºï¼ˆå¸¦é¢œè‰²ï¼‰
logger.add(
    sys.stdout,
    colorize=True,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | {message}",
    level="INFO"
)

# æ–‡ä»¶è¾“å‡ºï¼ˆå¯é€‰ï¼ŒGitHub Actions ä¸­é€šå¸¸ä¸éœ€è¦ï¼‰
# logger.add("runtime.log", level="DEBUG", rotation="10 MB")
```

---

## ç¯å¢ƒå˜é‡

### å¿…éœ€

| å˜é‡ | è¯´æ˜ |
|------|------|
| `EMAIL_USER` | QQ é‚®ç®±è´¦å· |
| `EMAIL_PASS` | QQ é‚®ç®±æˆæƒç ï¼ˆ16ä½ï¼Œä¸æ˜¯ç™»å½•å¯†ç ï¼‰ |
| `EMAIL_TO` | æ¥æ”¶é€šçŸ¥çš„é‚®ç®± |

### å¯é€‰

| å˜é‡ | è¯´æ˜ |
|------|------|
| `EMAIL_SENDER` | å‘ä»¶äººæ˜¾ç¤ºåç§° |
| `PUSHPLUS_TOKEN` | PushPlus Token |
| `SC3_PUSH_KEY` | Serveré…± Turbo SendKey |
| `TELEGRAM_BOT_TOKEN` | Telegram Bot Token |
| `TELEGRAM_CHAT_ID` | Telegram Chat ID |

---

## æ³¨æ„äº‹é¡¹ï¼ˆé¿å‘æŒ‡å—ï¼‰

### åçˆ¬ç›¸å…³

1. **å¿…é¡»ä½¿ç”¨ Patchright** - CAAC å®˜ç½‘æœ‰å®‰å…¨ç‹—é˜²æŠ¤ï¼Œæ™®é€š Playwright ä¼šè¢«æ‹¦æˆª
2. **è®¾ç½®éšæœºå»¶è¿Ÿ** - è¯·æ±‚é—´éš” 2-5 ç§’ï¼Œé¿å…è§¦å‘é™æµ
   ```python
   import random
   import time
   time.sleep(random.uniform(2, 5))
   ```
3. **æ¨¡æ‹ŸçœŸå® User-Agent** - Patchright å·²è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€é¢å¤–é…ç½®
4. **å¤„ç† networkidle** - ä½¿ç”¨ `wait_until="networkidle"` ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½

### GitHub Actions ç›¸å…³

1. **Cron ä¸å‡†æ—¶** - å¯èƒ½å»¶è¿Ÿå‡ ååˆ†é’Ÿï¼Œä¸è¦ä¾èµ–ç²¾ç¡®æ—¶é—´
2. **60 å¤©è‡ªåŠ¨ç¦ç”¨** - é•¿æœŸæ— æ´»åŠ¨ä¼šè¢«ç¦ç”¨ï¼Œéœ€æ‰‹åŠ¨é‡å¯
3. **IP å¯èƒ½è¢«å°** - GitHub Actions ä½¿ç”¨å…¬å…± IP æ®µï¼Œå¦‚è¢«å°éœ€è€ƒè™‘ä»£ç†
4. **é…é¢é™åˆ¶** - ç§æœ‰ä»“åº“æ¯æœˆ 2000 åˆ†é’Ÿï¼Œæ³¨æ„æ§åˆ¶è¿è¡Œæ—¶é•¿

### QQ é‚®ç®±ç›¸å…³

1. **ä½¿ç”¨æˆæƒç ** - ä¸æ˜¯ç™»å½•å¯†ç ï¼Œåœ¨ QQ é‚®ç®±è®¾ç½®ä¸­ç”Ÿæˆ
2. **From å­—æ®µæ ¼å¼** - å¿…é¡»ç”¨ `formataddr()` æ ¼å¼åŒ–ï¼Œå¦åˆ™ 502 é”™è¯¯
3. **ä½¿ç”¨ SSL 465 ç«¯å£** - ä¸æ˜¯ 587ï¼Œä¸éœ€è¦ STARTTLS
4. **é¿å…é¢‘ç¹å‘é€** - ç›¸åŒå†…å®¹é¢‘ç¹å‘é€ä¼šè¢«åˆ¤å®šä¸ºåƒåœ¾é‚®ä»¶

### JSON æ–‡ä»¶ç›¸å…³

1. **ensure_ascii=False** - å¦åˆ™ä¸­æ–‡å˜æˆ `\uXXXX`
2. **encoding="utf-8"** - å¿…é¡»æ˜¾å¼æŒ‡å®š
3. **åŸå­å†™å…¥** - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ + `os.replace()` é˜²æ­¢æ•°æ®æŸå

### BeautifulSoup ç›¸å…³

1. **ä½¿ç”¨ response.content** - ä¸æ˜¯ response.textï¼Œè®© BS4 è‡ªåŠ¨æ£€æµ‹ç¼–ç 
2. **æŒ‡å®šè§£æå™¨** - æ¨è `"lxml"`ï¼Œæ¯” `"html.parser"` æ›´å¿«æ›´ç¨³å®š
3. **å¤„ç†ç¼–ç å¤±è´¥** - å¦‚æœä¹±ç ï¼Œå°è¯• `from_encoding="gb18030"`

---

## å¼€å‘æ­¥éª¤å»ºè®®

### ç¬¬ä¸€æ­¥ï¼šå®ç° crawler.py

1. å¤ç”¨ `regulation_service.py` çš„è§£æé€»è¾‘
2. ä½¿ç”¨ Patchright åŒæ­¥ API è·å–é¡µé¢
3. å®ç° `CaacCrawler` ç±»ï¼ŒåŒ…å«ï¼š
   - `fetch_regulations()` - è·å–è§„ç« åˆ—è¡¨
   - `fetch_normatives()` - è·å–è§„èŒƒæ€§æ–‡ä»¶åˆ—è¡¨
   - `download_pdf()` - ä¸‹è½½ PDF æ–‡ä»¶

### ç¬¬äºŒæ­¥ï¼šå®ç° storage.py

1. JSON æ–‡ä»¶è¯»å†™ï¼ˆåŸå­å†™å…¥ï¼‰
2. å˜æ›´æ£€æµ‹é€»è¾‘ï¼š
   - æ–°å¢ï¼šURL ä¸å­˜åœ¨äºå†å²è®°å½•
   - æ›´æ–°ï¼šURL å­˜åœ¨ä½†å†…å®¹å˜åŒ–ï¼ˆå¯é€‰ï¼Œé€šè¿‡ SHA256ï¼‰
3. å®ç° `Storage` ç±»ï¼ŒåŒ…å«ï¼š
   - `load()` - åŠ è½½å†å²çŠ¶æ€
   - `save()` - ä¿å­˜çŠ¶æ€ï¼ˆåŸå­å†™å…¥ï¼‰
   - `detect_changes()` - æ£€æµ‹å˜æ›´

### ç¬¬ä¸‰æ­¥ï¼šå®ç° notifier.py

1. å¤ç”¨ `sign-in/utils/notify.py` çš„é‚®ä»¶å‘é€é€»è¾‘
2. ç®€åŒ–ä¸ºåªæ”¯æŒ Email + PushPlusï¼ˆå¯é€‰ï¼‰
3. å®ç° `Notifier` ç±»ï¼ŒåŒ…å«ï¼š
   - `send_email()` - å‘é€é‚®ä»¶
   - `format_message()` - æ ¼å¼åŒ–å˜æ›´æ¶ˆæ¯

### ç¬¬å››æ­¥ï¼šå®ç° main.py

1. ä¸²è”æ•´ä¸ªæµç¨‹
2. é”™è¯¯å¤„ç†å’Œæ—¥å¿—
3. ä¸»å‡½æ•°é€»è¾‘ï¼š
   ```python
   def main():
       # 1. çˆ¬å–æœ€æ–°è§„ç« åˆ—è¡¨
       # 2. åŠ è½½å†å²çŠ¶æ€
       # 3. æ£€æµ‹å˜æ›´
       # 4. å¦‚æœ‰å˜æ›´ï¼šä¸‹è½½ PDF + å‘é€é€šçŸ¥
       # 5. ä¿å­˜æ–°çŠ¶æ€
   ```

### ç¬¬äº”æ­¥ï¼šæœ¬åœ°æµ‹è¯•

```bash
# å®‰è£…ä¾èµ–
uv sync

# å®‰è£…æµè§ˆå™¨
uv run patchright install chromium

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
export EMAIL_USER="your_qq@qq.com"
export EMAIL_PASS="your_16_char_auth_code"
export EMAIL_TO="receiver@example.com"

# è¿è¡Œ
uv run python src/main.py
```

### ç¬¬å…­æ­¥ï¼šæ¨é€åˆ° GitHub

1. åœ¨ä»“åº“ Settings â†’ Secrets ä¸­é…ç½®ç¯å¢ƒå˜é‡
2. æ‰‹åŠ¨è§¦å‘ workflow æµ‹è¯•
3. æ£€æŸ¥ Actions æ—¥å¿—ç¡®è®¤è¿è¡Œæ­£å¸¸

---

## æµ‹è¯•å‘½ä»¤

```bash
# å®‰è£…ä¾èµ–
uv sync

# å®‰è£…æµè§ˆå™¨
uv run patchright install chromium

# è¿è¡Œå®Œæ•´æµç¨‹
uv run python src/main.py

# åªæµ‹è¯•çˆ¬è™«
uv run python -c "
from src.crawler import CaacCrawler
crawler = CaacCrawler()
docs = crawler.fetch_regulations()
print(f'æ‰¾åˆ° {len(docs)} æ¡è§„ç« ')
for doc in docs[:3]:
    print(f'  - {doc.doc_number} {doc.title}')
"

# åªæµ‹è¯•é‚®ä»¶å‘é€
uv run python -c "
import os
from src.notifier import Notifier
notifier = Notifier()
notifier.send_email('æµ‹è¯•ä¸»é¢˜', 'æµ‹è¯•å†…å®¹')
"
```

---

## é™„å½•ï¼šå®Œæ•´ä»£ç ç»“æ„

```
CCAR-workflow/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ check-updates.yml    # GitHub Actions å·¥ä½œæµ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              # ç©ºæ–‡ä»¶
â”‚   â”œâ”€â”€ crawler.py               # CAAC çˆ¬è™«
â”‚   â”‚   â”œâ”€â”€ RegulationDocument   # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ CaacCrawler          # çˆ¬è™«ç±»
â”‚   â”‚   â””â”€â”€ generate_filename()  # æ–‡ä»¶åç”Ÿæˆ
â”‚   â”œâ”€â”€ storage.py               # çŠ¶æ€å­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ Storage              # å­˜å‚¨ç±»
â”‚   â”‚   â””â”€â”€ atomic_write_json()  # åŸå­å†™å…¥
â”‚   â”œâ”€â”€ notifier.py              # é€šçŸ¥ç®¡ç†
â”‚   â”‚   â””â”€â”€ Notifier             # é€šçŸ¥ç±»
â”‚   â””â”€â”€ main.py                  # ä¸»å…¥å£
â”‚       â””â”€â”€ main()               # ä¸»å‡½æ•°
â”œâ”€â”€ data/
â”‚   â””â”€â”€ regulations.json         # è§„ç« çŠ¶æ€æ•°æ®
â”œâ”€â”€ downloads/                   # PDF ä¸‹è½½ç›®å½•ï¼ˆ.gitignoreï¼‰
â”œâ”€â”€ pyproject.toml               # é¡¹ç›®ä¾èµ–
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                    # ç”¨æˆ·æ–‡æ¡£
â””â”€â”€ DEVELOPMENT.md               # å¼€å‘æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```


---

## é™„å½•ï¼šCAAC å®˜ç½‘ HTML è§£æç»†èŠ‚

### æœç´¢æ¥å£å‚æ•°

```
https://www.caac.gov.cn/was5/web/search?
  channelid=269689     # é¢‘é“ IDï¼ˆè§„ç« : 269689, è§„èŒƒæ€§æ–‡ä»¶: 238066ï¼‰
  &perpage=100         # æ¯é¡µæ•°é‡
  &orderby=-fabuDate   # æŒ‰å‘å¸ƒæ—¥æœŸé™åº
  &fl=13               # åˆ†ç±» IDï¼ˆè§„ç« : 13, è§„èŒƒæ€§æ–‡ä»¶: 14ï¼‰
  &sw=å…³é”®è¯           # æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
  &fwrq1=2024-01-01    # å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
  &fwrq2=2024-12-31    # ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
```

### è§„ç« åˆ—è¡¨é¡µ HTML ç»“æ„

```html
<table class="t_table">
  <tbody>
    <tr>
      <td>åºå·</td>
      <td class="t_l">
        <a href="/XXGK/XXGK/MHGZ/202401/t20240115_xxx.html">è§„ç« æ ‡é¢˜</a>
        <div class="t_l_content">
          <li>åŠæ–‡å•ä½ï¼šä¸­å›½æ°‘ç”¨èˆªç©ºå±€</li>
          <li>å‘æ–‡æ—¥æœŸï¼š2024å¹´01æœˆ15æ—¥</li>
          <li>æœ‰æ•ˆæ€§ï¼šæœ‰æ•ˆ</li>
        </div>
      </td>
      <td>CCAR-91-R4</td>  <!-- æ–‡å· -->
      <td>æœ‰æ•ˆ</td>         <!-- æœ‰æ•ˆæ€§ -->
    </tr>
  </tbody>
</table>
```

### è§£æè§„ç« åˆ—è¡¨çš„å…³é”®ä»£ç 

```python
def parse_regulation_page(html_content: str) -> list[RegulationDocument]:
    """è§£æè§„ç« æœç´¢ç»“æœé¡µé¢"""
    soup = BeautifulSoup(html_content, "lxml")
    documents = []
    
    # æŸ¥æ‰¾è¡¨æ ¼
    table = soup.find("table", class_="t_table")
    if not table:
        return documents
    
    # éå†è¡Œ
    tbody = table.find("tbody")
    rows = tbody.find_all("tr") if tbody else table.find_all("tr")[1:]
    
    for row in rows:
        cells = row.find_all("td")
        if len(cells) < 4:
            continue
        
        # æ ‡é¢˜å’Œé“¾æ¥
        title_cell = row.find("td", class_="t_l") or cells[1]
        link = title_cell.find("a", href=True)
        if not link:
            continue
        
        title = link.get_text(strip=True)
        url = urljoin(BASE_URL, link.get("href", ""))
        
        # æ–‡å·
        doc_number = cells[2].get_text(strip=True) if len(cells) > 2 else ""
        
        # æœ‰æ•ˆæ€§
        validity = cells[3].get_text(strip=True) if len(cells) > 3 else ""
        
        # ä»è¯¦æƒ… div æå–æ›´å¤šä¿¡æ¯
        detail_div = title_cell.find("div", class_="t_l_content")
        office_unit = ""
        publish_date = ""
        
        if detail_div:
            for li in detail_div.find_all("li"):
                text = li.get_text(strip=True)
                if "åŠæ–‡å•ä½ï¼š" in text:
                    office_unit = text.replace("åŠæ–‡å•ä½ï¼š", "").strip()
                elif "å‘æ–‡æ—¥æœŸï¼š" in text or "å‘æ–‡æ—¥æœŸ:" in text:
                    # è§£ææ—¥æœŸï¼š2024å¹´01æœˆ15æ—¥ -> 2024-01-15
                    date_text = re.sub(r"å‘æ–‡æ—¥æœŸ[ï¼š:]", "", text).strip()
                    publish_date = normalize_date(date_text)
        
        documents.append(RegulationDocument(
            title=title,
            url=url,
            validity=validity,
            doc_number=doc_number,
            office_unit=office_unit,
            doc_type="regulation",
            publish_date=publish_date,
        ))
    
    return documents


def normalize_date(date_str: str) -> str:
    """æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼ï¼š2024å¹´01æœˆ15æ—¥ -> 2024-01-15"""
    if not date_str:
        return ""
    
    match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', date_str)
    if match:
        year, month, day = match.groups()
        return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
    
    # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼
    if re.match(r'\d{4}-\d{2}-\d{2}', date_str):
        return date_str
    
    return date_str
```

### ä» URL æå–æ—¥æœŸ

CAAC å®˜ç½‘çš„ URL é€šå¸¸åŒ…å«æ—¥æœŸä¿¡æ¯ï¼š

```
/XXGK/XXGK/MHGZ/202401/t20240115_xxx.html
                       ^^^^^^^^
                       æ—¥æœŸéƒ¨åˆ†
```

```python
def extract_date_from_url(url: str) -> str:
    """ä» URL æå–æ—¥æœŸ"""
    match = re.search(r'/t(\d{4})(\d{2})(\d{2})_', url)
    if match:
        year, month, day = match.groups()
        return f"{year}-{month}-{day}"
    return ""
```

### è¯¦æƒ…é¡µ PDF é“¾æ¥æŸ¥æ‰¾

```python
def find_pdf_link(soup: BeautifulSoup, doc_url: str) -> str | None:
    """åœ¨è¯¦æƒ…é¡µæŸ¥æ‰¾ PDF ä¸‹è½½é“¾æ¥"""
    
    # æ¨¡å¼1: æŸ¥æ‰¾é™„ä»¶åŒºåŸŸ
    attachment_texts = soup.find_all(string=re.compile(r'é™„ä»¶[ï¼š:]?', re.I))
    for text in attachment_texts:
        parent = text.parent
        if parent:
            container = parent.parent or parent
            links = container.find_all('a', href=re.compile(r'\.pdf$', re.I))
            if links:
                return build_full_url(links[0].get('href'), doc_url)
    
    # æ¨¡å¼2: ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰ PDF é“¾æ¥
    links = soup.find_all('a', href=re.compile(r'\.pdf$', re.I))
    if links:
        return build_full_url(links[0].get('href'), doc_url)
    
    return None


def build_full_url(link: str, doc_url: str) -> str:
    """æ„å»ºå®Œæ•´ URL"""
    if link.startswith('http'):
        return link
    
    if link.startswith('/'):
        # ç»å¯¹è·¯å¾„
        from urllib.parse import urlparse
        parsed = urlparse(doc_url)
        return f"{parsed.scheme}://{parsed.netloc}{link}"
    
    # ç›¸å¯¹è·¯å¾„
    doc_dir = '/'.join(doc_url.split('/')[:-1])
    
    # å¤„ç† ../ å’Œ ./
    while link.startswith('../'):
        link = link[3:]
        doc_dir = '/'.join(doc_dir.split('/')[:-1])
    
    if link.startswith('./'):
        link = link[2:]
    
    return f"{doc_dir}/{link}"
```

---

## é™„å½•ï¼šé‚®ä»¶é€šçŸ¥æ¨¡æ¿

### HTML é‚®ä»¶æ¨¡æ¿ç¤ºä¾‹

```html
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background: #1a73e8; color: white; padding: 20px; border-radius: 8px 8px 0 0; }
        .content { background: #f8f9fa; padding: 20px; border-radius: 0 0 8px 8px; }
        .item { background: white; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #1a73e8; }
        .item-title { font-weight: bold; color: #1a73e8; }
        .item-meta { color: #666; font-size: 14px; margin-top: 5px; }
        .download-btn { display: inline-block; background: #1a73e8; color: white; padding: 8px 16px; border-radius: 4px; text-decoration: none; margin-top: 10px; }
        .footer { text-align: center; color: #999; font-size: 12px; margin-top: 20px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h2>ğŸ“‹ CAAC è§„ç« æ›´æ–°é€šçŸ¥</h2>
            <p>æ£€æµ‹åˆ° {count} æ¡æ–°è§„ç« /è§„èŒƒæ€§æ–‡ä»¶</p>
        </div>
        <div class="content">
            {items}
        </div>
        <div class="footer">
            <p>æ­¤é‚®ä»¶ç”± CAAC è§„ç« ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨å‘é€</p>
            <p>æ£€æµ‹æ—¶é—´ï¼š{timestamp}</p>
        </div>
    </div>
</body>
</html>
```

### å•æ¡è§„ç« æ¨¡æ¿

```html
<div class="item">
    <div class="item-title">{doc_number} {title}</div>
    <div class="item-meta">
        ğŸ“… å‘å¸ƒæ—¥æœŸï¼š{publish_date} | 
        ğŸ¢ å‘å¸ƒå•ä½ï¼š{office_unit} | 
        âœ… çŠ¶æ€ï¼š{validity}
    </div>
    <a href="{pdf_url}" class="download-btn">ğŸ“¥ ä¸‹è½½ PDF</a>
</div>
```
